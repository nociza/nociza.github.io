[
  {
    "id": "221cb2de-72bc-80fc-b11f-f7864597aa0d",
    "arxivId": "2505.05522",
    "url": "https://arxiv.org/abs/2505.05522",
    "title": "Continuous Thought Machines",
    "authors": [
      "Luke Darlow",
      "Ciaran Regan",
      "Sebastian Risi",
      "Jeffrey Seely",
      "Llion Jones"
    ],
    "abstract": "Biological brains demonstrate complex neural activity, where the timing and interplay between neurons is critical to how brains process information. Most deep learning architectures simplify neural activity by abstracting away temporal dynamics. In this paper we challenge that paradigm. By incorporating neuron-level processing and synchronization, we can effectively reintroduce neural timing as a foundational element. We present the Continuous Thought Machine (CTM), a model designed to leverage neural dynamics as its core representation. The CTM has two core innovations: (1) neuron-level temporal processing, where each neuron uses unique weight parameters to process a history of incoming signals; and (2) neural synchronization employed as a latent representation. The CTM aims to strike a balance between oversimplified neuron abstractions that improve computational efficiency, and biological realism. It operates at a level of abstraction that effectively captures essential temporal dynamics while remaining computationally tractable for deep learning. We demonstrate the CTM's strong performance and versatility across a range of challenging tasks, including ImageNet-1K classification, solving 2D mazes, sorting, parity computation, question-answering, and RL tasks. Beyond displaying rich internal representations and offering a natural avenue for interpretation owing to its internal process, the CTM is able to perform tasks that require complex sequential reasoning. The CTM can also leverage adaptive compute, where it can stop earlier for simpler tasks, or keep computing when faced with more challenging instances. The goal of this work is to share the CTM and its associated innovations, rather than pushing for new state-of-the-art results. To that end, we believe the CTM represents a significant step toward developing more biologically plausible and powerful artificial intelligence systems.",
    "publishedDate": "2025-05-08T06:31:54Z",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "status": "Done"
  },
  {
    "id": "203cb2de-72bc-80f0-94ab-eb34c700b90a",
    "arxivId": "2010.15980",
    "url": "https://arxiv.org/abs/2010.15980",
    "title": "AutoPrompt: Eliciting Knowledge from Language Models with Automatically\n  Generated Prompts",
    "authors": [
      "Taylor Shin",
      "Yasaman Razeghi",
      "Robert L. Logan IV",
      "Eric Wallace",
      "Sameer Singh"
    ],
    "abstract": "The remarkable success of pretrained language models has motivated the study of what kinds of knowledge these models learn during pretraining. Reformulating tasks as fill-in-the-blanks problems (e.g., cloze tests) is a natural approach for gauging such knowledge, however, its usage is limited by the manual effort and guesswork required to write suitable prompts. To address this, we develop AutoPrompt, an automated method to create prompts for a diverse set of tasks, based on a gradient-guided search. Using AutoPrompt, we show that masked language models (MLMs) have an inherent capability to perform sentiment analysis and natural language inference without additional parameters or finetuning, sometimes achieving performance on par with recent state-of-the-art supervised models. We also show that our prompts elicit more accurate factual knowledge from MLMs than the manually created prompts on the LAMA benchmark, and that MLMs can be used as relation extractors more effectively than supervised relation extraction models. These results demonstrate that automatically generated prompts are a viable parameter-free alternative to existing probing methods, and as pretrained LMs become more sophisticated and capable, potentially a replacement for finetuning.",
    "publishedDate": "2020-10-29T22:54:00Z",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "status": "Done"
  },
  {
    "id": "203cb2de-72bc-8022-b4da-fd473a6f83ea",
    "arxivId": "2412.05299",
    "url": "https://arxiv.org/abs/2412.05299",
    "title": "Specifications: The missing link to making the development of LLM\n  systems an engineering discipline",
    "authors": [
      "Ion Stoica",
      "Matei Zaharia",
      "Joseph Gonzalez",
      "Ken Goldberg",
      "Koushik Sen",
      "Hao Zhang",
      "Anastasios Angelopoulos",
      "Shishir G. Patil",
      "Lingjiao Chen",
      "Wei-Lin Chiang",
      "Jared Q. Davis"
    ],
    "abstract": "Despite the significant strides made by generative AI in just a few short years, its future progress is constrained by the challenge of building modular and robust systems. This capability has been a cornerstone of past technological revolutions, which relied on combining components to create increasingly sophisticated and reliable systems. Cars, airplanes, computers, and software consist of components-such as engines, wheels, CPUs, and libraries-that can be assembled, debugged, and replaced. A key tool for building such reliable and modular systems is specification: the precise description of the expected behavior, inputs, and outputs of each component. However, the generality of LLMs and the inherent ambiguity of natural language make defining specifications for LLM-based components (e.g., agents) both a challenging and urgent problem. In this paper, we discuss the progress the field has made so far-through advances like structured outputs, process supervision, and test-time compute-and outline several future directions for research to enable the development of modular and reliable LLM-based systems through improved specifications.",
    "publishedDate": "2024-11-25T07:48:31Z",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "status": "Done"
  }
]